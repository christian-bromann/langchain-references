# Build IR Workflow
#
# Builds IR artifacts for all LangChain ecosystem projects.
# Uses a matrix strategy to build each package in parallel for maximum speed.
#
# The workflow is optimized to skip builds when no new releases exist:
# - Compares build creation date against manually-configured version metadata
# - Only builds packages that have new versions available
# - Use `pnpm sync-versions` locally to update version metadata when needed
#
# Triggers:
# - Manual dispatch with optional project/language filters
# - Scheduled daily builds
# - Push to main (for testing workflow changes)

name: Build IR

on:
  # Manual trigger with optional filters
  workflow_dispatch:
    inputs:
      project:
        description: 'Project to build (leave empty for all)'
        required: false
        type: choice
        options:
          - ''
          - langchain
          - langgraph
          - deepagent
      language:
        description: 'Language to build (leave empty for all)'
        required: false
        type: choice
        options:
          - ''
          - python
          - typescript
      with_versions:
        description: 'Include version history tracking'
        required: false
        type: boolean
        default: true
      full_rebuild:
        description: 'Force full rebuild (ignore existing changelogs)'
        required: false
        type: boolean
        default: false
      force_build:
        description: 'Force build even if no new releases detected'
        required: false
        type: boolean
        default: false

  # Trigger on upstream releases (via repository_dispatch)
  repository_dispatch:
    types: [upstream-release]

  # Build on push to main (workflow, extractor, or config changes)
  push:
    branches:
      - main
    paths:
      - '.github/workflows/build-ir.yml'
      - 'configs/**'
      - 'packages/build-pipeline/**'
      - 'packages/extractor-*/**'
      - 'packages/ir-schema/**'

# Ensure only one build runs at a time per ref
concurrency:
  group: build-ir-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # Determine which packages to build based on inputs
  # Each package gets its own parallel runner for maximum speed
  matrix:
    name: Generate Build Matrix
    runs-on: ubuntu-latest
    outputs:
      packages: ${{ steps.generate.outputs.packages }}
    steps:
      - uses: actions/checkout@v4

      - name: Generate package-level matrix
        id: generate
        run: |
          # Build the list of packages from config files
          PROJECT="${{ github.event.inputs.project }}"
          LANGUAGE="${{ github.event.inputs.language }}"

          # Generate matrix entries from config files
          PACKAGES="[]"

          for config_file in configs/*-python.json configs/*-typescript.json; do
            # Skip if no files match
            [ -f "$config_file" ] || continue

            # Skip schema file
            [[ "$config_file" == *"config-schema"* ]] && continue

            config_name=$(basename "$config_file")
            file_project=$(echo "$config_name" | sed 's/-\(python\|typescript\)\.json$//')
            file_language=$(echo "$config_name" | sed 's/.*-\(python\|typescript\)\.json$/\1/')

            # Apply project filter
            if [ -n "$PROJECT" ] && [ "$file_project" != "$PROJECT" ]; then
              continue
            fi

            # Apply language filter
            if [ -n "$LANGUAGE" ] && [ "$file_language" != "$LANGUAGE" ]; then
              continue
            fi

            # Extract packages from config file
            packages_in_config=$(jq -r '.packages[].name' "$config_file")

            for pkg in $packages_in_config; do
              entry=$(jq -n \
                --arg project "$file_project" \
                --arg language "$file_language" \
                --arg config "$config_name" \
                --arg package "$pkg" \
                '{project: $project, language: $language, config: $config, package: $package}')
              PACKAGES=$(echo "$PACKAGES" | jq -c ". + [$entry]")
            done
          done

          echo "packages=$PACKAGES" >> $GITHUB_OUTPUT
          echo "Building $(echo "$PACKAGES" | jq length) packages in parallel:"
          echo "$PACKAGES" | jq -r '.[] | "  - \(.project)/\(.language)/\(.package)"'

  # Build each package in parallel for maximum speed
  build:
    name: ${{ matrix.package }} (${{ matrix.language }})
    needs: matrix
    runs-on: ubuntu-latest
    # Skip if no packages to build (e.g., bad filter)
    if: ${{ needs.matrix.outputs.packages != '[]' }}
    strategy:
      fail-fast: false
      max-parallel: 20  # GitHub allows up to 256 concurrent jobs
      matrix:
        include: ${{ fromJson(needs.matrix.outputs.packages) }}

    env:
      BLOB_READ_WRITE_TOKEN: ${{ secrets.BLOB_READ_WRITE_TOKEN }}

    steps:
      - uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version-file: .nvmrc
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Free disk space
        run: |
          echo "Before cleanup:"
          df -h /
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /usr/local/lib/android
          sudo rm -rf /opt/ghc
          sudo rm -rf /opt/hostedtoolcache/CodeQL
          sudo rm -rf /usr/local/share/boost
          echo "After cleanup:"
          df -h /

      - name: Setup Python (for Python builds)
        if: matrix.language == 'python'
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Python extractor (for Python builds)
        if: matrix.language == 'python'
        run: |
          cd packages/extractor-python
          pip install -e .

      - name: Build IR for ${{ matrix.package }}
        id: build
        run: |
          FLAGS=""

          # Add versioning flag if enabled (default: true)
          if [ "${{ inputs.with_versions }}" != "false" ]; then
            FLAGS="$FLAGS --with-versions"
          fi

          # Add full rebuild flag if requested
          if [ "${{ inputs.full_rebuild }}" == "true" ]; then
            FLAGS="$FLAGS --full"
          fi

          # Force build for push events (code changes) or when force_build is set
          if [ "${{ github.event_name }}" == "push" ] || [ "${{ inputs.force_build }}" == "true" ]; then
            FLAGS="$FLAGS --force"
          fi

          # Run via tsx directly with package filter for parallel execution
          # Each runner builds only ONE package for maximum parallelization
          npx tsx packages/build-pipeline/src/commands/build-ir.ts \
            --config ./configs/${{ matrix.config }} \
            --package "${{ matrix.package }}" \
            --skip-pointers \
            $FLAGS
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          BLOB_BASE_URL: ${{ vars.BLOB_BASE_URL }}

      - name: Prepare artifact name
        id: artifact
        run: |
          # Sanitize package name for artifact (replace @ and / with safe characters)
          # e.g., @langchain/core -> langchain-core
          SAFE_NAME=$(echo "${{ matrix.package }}" | sed 's/@//g' | sed 's/\//-/g' | sed 's/\./-/g')
          echo "name=ir-${{ matrix.project }}-${{ matrix.language }}-${SAFE_NAME}" >> $GITHUB_OUTPUT

      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: ${{ steps.artifact.outputs.name }}
          path: |
            ir-output/
            !ir-output/latest-*
          retention-days: 7
          if-no-files-found: ignore

  # Update pointers after all builds complete
  # This job merges package artifacts and updates build pointers
  update-pointers:
    name: Update Build Pointers
    needs: [matrix, build]
    runs-on: ubuntu-latest
    # Run if build succeeded (even if some were skipped)
    if: ${{ !cancelled() && needs.build.result == 'success' }}

    env:
      BLOB_READ_WRITE_TOKEN: ${{ secrets.BLOB_READ_WRITE_TOKEN }}

    steps:
      - uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version-file: .nvmrc
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Download all artifacts
        id: download
        uses: actions/download-artifact@v4
        with:
          path: artifacts/
          merge-multiple: true
        continue-on-error: true

      - name: Check for artifacts
        id: check-artifacts
        run: |
          # Artifacts are uploaded as ir-output/{buildId}/...
          # When merged, they become artifacts/ir-output/{buildId}/...
          # OR artifacts/{buildId}/... depending on how they were uploaded

          # Check both possible structures
          if [ -d "artifacts/ir-output" ]; then
            IR_PATH="artifacts/ir-output"
          elif [ -d "artifacts" ] && [ "$(ls -A artifacts 2>/dev/null)" ]; then
            IR_PATH="artifacts"
          else
            echo "has_artifacts=false" >> $GITHUB_OUTPUT
            echo "No artifacts found - all builds were skipped"
            exit 0
          fi

          echo "ir_path=$IR_PATH" >> $GITHUB_OUTPUT
          echo "has_artifacts=true" >> $GITHUB_OUTPUT
          echo "Found artifacts in $IR_PATH:"
          find "$IR_PATH" -name "reference.manifest.json" | head -20

      - name: Merge manifests and update pointers
        if: steps.check-artifacts.outputs.has_artifacts == 'true'
        run: |
          # With package-level parallelization and incremental builds, we need to:
          # 1. For each build, collect packages from the artifacts
          # 2. MERGE with existing packages from blob storage (for packages that weren't rebuilt)
          # 3. Update pointers with the complete manifest
          #
          # This is critical because incremental builds only include packages that had updates,
          # but the manifest needs ALL packages for the web app to work correctly.

          IR_PATH="${{ steps.check-artifacts.outputs.ir_path }}"
          BLOB_URL="${BLOB_BASE_URL:-}"

          # Find all unique build directories
          for build_dir in "$IR_PATH"/*/; do
            [ -d "$build_dir" ] || continue

            BUILD_ID=$(basename "$build_dir")

            # Skip symlinks and latest-* directories
            if [ -L "$build_dir" ] || [[ "$BUILD_ID" == latest-* ]]; then
              continue
            fi

            manifest="$build_dir/reference.manifest.json"
            if [ ! -f "$manifest" ]; then
              echo "No manifest in $build_dir, skipping"
              continue
            fi

            # The merged artifact combines all packages with the same buildId
            # Each package's symbols are in packages/{packageId}/ subdirectories
            # Count how many packages are in this build
            pkg_count=$(find "$build_dir/packages" -name "symbols.json" 2>/dev/null | wc -l | tr -d ' ')

            echo "Build $BUILD_ID has $pkg_count new/updated package(s)"

            if [ "$pkg_count" -eq 0 ]; then
              echo "  No packages found, skipping"
              continue
            fi

            # Get base manifest info (irVersion, build, project, sources)
            base_manifest=$(cat "$manifest")
            project=$(echo "$base_manifest" | jq -r '.project // "langchain"')

            # Determine language from the first package
            first_pkg_lang=$(echo "$base_manifest" | jq -r '.packages[0].language // "typescript"')
            if [ "$first_pkg_lang" == "python" ]; then
              ecosystem="python"
            else
              ecosystem="javascript"
            fi

            echo "  Project: $project, Language: $ecosystem"

            # Try to fetch existing manifest from blob storage to merge with
            existing_packages="[]"
            if [ -n "$BLOB_URL" ]; then
              echo "  Fetching existing manifest from blob storage..."
              pointer_url="$BLOB_URL/pointers/latest-${project}-${ecosystem}.json"
              existing_pointer=$(curl -sf "$pointer_url" 2>/dev/null || echo '{}')
              existing_build_id=$(echo "$existing_pointer" | jq -r '.buildId // empty')

              if [ -n "$existing_build_id" ] && [ "$existing_build_id" != "$BUILD_ID" ]; then
                # Fetch the existing manifest
                existing_manifest_url="$BLOB_URL/ir/${existing_build_id}/reference.manifest.json"
                existing_manifest=$(curl -sf "$existing_manifest_url" 2>/dev/null || echo '{}')
                existing_packages=$(echo "$existing_manifest" | jq -c '.packages // []')
                existing_count=$(echo "$existing_packages" | jq 'length')
                echo "  Found $existing_count existing package(s) in blob storage (build: $existing_build_id)"
              else
                echo "  No existing build found or same build ID, starting fresh"
              fi
            else
              echo "  No BLOB_URL set, cannot fetch existing manifest"
            fi

            # Build new packages array from all symbols.json files in artifacts
            echo "  Processing new/updated packages from artifacts..."
            new_packages="[]"
            new_package_ids="[]"
            for symbols_file in "$build_dir"/packages/*/symbols.json; do
              [ -f "$symbols_file" ] || continue

              pkg_dir=$(dirname "$symbols_file")
              pkg_id=$(basename "$pkg_dir")

              # Extract package info from symbols.json
              pkg_info=$(jq -c '.package' "$symbols_file" 2>/dev/null || echo '{}')
              if [ "$pkg_info" != '{}' ] && [ "$pkg_info" != 'null' ]; then
                # Count symbols
                total=$(jq '.symbols | length' "$symbols_file")
                classes=$(jq '[.symbols[] | select(.kind == "class")] | length' "$symbols_file")
                functions=$(jq '[.symbols[] | select(.kind == "function")] | length' "$symbols_file")
                modules=$(jq '[.symbols[] | select(.kind == "module")] | length' "$symbols_file")
                types=$(jq '[.symbols[] | select(.kind == "interface" or .kind == "typeAlias" or .kind == "enum")] | length' "$symbols_file")

                # Build package entry (simplified - uses existing package info)
                pkg_entry=$(echo "$pkg_info" | jq -c --arg pid "$pkg_id" \
                  --argjson total "$total" --argjson classes "$classes" \
                  --argjson functions "$functions" --argjson modules "$modules" \
                  --argjson types "$types" \
                  '. + {
                    packageId: $pid,
                    stats: {total: $total, classes: $classes, functions: $functions, modules: $modules, types: $types},
                    nav: {rootGroups: ["Classes", "Functions", "Types"]},
                    entry: {kind: "module", refId: ""}
                  }')
                new_packages=$(echo "$new_packages" | jq -c ". + [$pkg_entry]")
                new_package_ids=$(echo "$new_package_ids" | jq -c ". + [\"$pkg_id\"]")
                echo "    + $pkg_id ($total symbols)"
              else
                echo "    Warning: Could not extract package info from $symbols_file"
              fi
            done

            # Merge: Start with new packages, then add existing packages that weren't updated
            merged_packages="$new_packages"
            if [ "$existing_packages" != "[]" ]; then
              echo "  Merging with existing packages..."
              # Add existing packages that aren't in the new set
              while IFS= read -r existing_pkg; do
                [ -z "$existing_pkg" ] && continue
                existing_id=$(echo "$existing_pkg" | jq -r '.packageId')
                # Check if this package was updated (is in new_package_ids)
                is_updated=$(echo "$new_package_ids" | jq --arg id "$existing_id" 'any(. == $id)')
                if [ "$is_updated" == "false" ]; then
                  merged_packages=$(echo "$merged_packages" | jq -c ". + [$existing_pkg]")
                  echo "    = $existing_id (kept from existing)"
                fi
              done < <(echo "$existing_packages" | jq -c '.[]')
            fi

            merged_count=$(echo "$merged_packages" | jq 'length')
            echo "  Final manifest has $merged_count package(s)"

            # Update manifest with merged packages array
            echo "$base_manifest" | jq --argjson pkgs "$merged_packages" '.packages = $pkgs' > "$manifest"

            echo "Updating pointers for build: $BUILD_ID"
            npx tsx packages/build-pipeline/src/commands/update-pointers.ts "$BUILD_ID" "$manifest"
          done
        env:
          BLOB_BASE_URL: ${{ vars.BLOB_BASE_URL }}

      - name: Report skipped
        if: steps.check-artifacts.outputs.has_artifacts == 'false'
        run: |
          echo "## Pointer Update Skipped" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "No new builds were created - all packages are already up to date." >> $GITHUB_STEP_SUMMARY

  # Summary job
  summary:
    name: Build Summary
    needs: [matrix, build, update-pointers]
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Check results
        run: |
          echo "## Build Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Job | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Matrix | ${{ needs.matrix.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Build | ${{ needs.build.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Update Pointers | ${{ needs.update-pointers.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ "${{ needs.build.result }}" == "success" ]; then
            echo "✅ All builds completed successfully!" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ needs.build.result }}" == "skipped" ]; then
            echo "⏭️ Builds were skipped (no updates needed)" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ Some builds failed. Check the logs for details." >> $GITHUB_STEP_SUMMARY
            exit 1
          fi
